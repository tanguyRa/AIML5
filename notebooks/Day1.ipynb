{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About me\n",
    "![Flexper, innovation on demand](img/flexper_logo_large.jpg)\n",
    "\n",
    "My name is **Tanguy Racinet** and I currently work at **Flexper**, a technological accelerator for startups.\n",
    "\n",
    "### How to reach me\n",
    "**mail**: tanguy@flexper.fr\n",
    "\n",
    "**linkedin**: https://www.linkedin.com/in/tanguyracinet/\n",
    "\n",
    "### Examples of projects I worked on\n",
    " * Movie rentals estimation and expected return on investment for movie streaming platform\n",
    " * Recommendation system for playlist generation in a streaming music platform \n",
    " * Vehicle expected return and pricing over time in car renting service\n",
    " * Pollution evolution in air traffic study for the DGAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics covered in the course - what you should know about by the end\n",
    "1. Generalities about Machine Learning\n",
    "2. Classification algorithms\n",
    "3. Recommender systems\n",
    "4. Linear regression\n",
    "5. Decision trees\n",
    "\n",
    "# Course overview - what we're actually going to do\n",
    "1. Day 1\n",
    "    * open Q&A\n",
    "    * Practice 1 - Generalities about Machine Learning\n",
    "    * Practice 2 - Classification algorithms\n",
    "2. Day 2\n",
    "    * open Q&A\n",
    "    * Practice - Recommender systems\n",
    "3. Day 3\n",
    "    * open Q&A\n",
    "    * Practice 1 - Decision trees\n",
    "    * Practice 2 - Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML generalities\n",
    "\n",
    "### Data splitting: Training, validation, test\n",
    "You should **never** evaluate your model on the data you used to train it. This is the best way to overfit your model and will produce disastrous results in production. We commonly divide the data in 2(3) distinct sets:\n",
    " * *training set* is used to train your algorithm\n",
    " * *test set* is used to evaluation your trained model and this is the data set you'll use to perform your evaluation metrics, such as confusion matrix and so on.\n",
    " * *validation set* is used when comparing multiple models or fine tuning hyper parameters. When dealing with small datasets, it is common to only use the training set to perform cross-validation using k-folding technique for instance.\n",
    "\n",
    "### Cross validation\n",
    "\n",
    "### Encoding\n",
    "Machine Learning models mostly operate with numerical values. However when dealing with real world data, there are plenty of different type involved. Encoding techniques are used to convert different kind of assets into numerical values. Here are a few examples of encoding techniques:\n",
    " * Label encoding\n",
    " * One hot encoding\n",
    " * Cyclical encoding\n",
    "\n",
    "### Missing value inputation\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "### ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification algorithms on Heart Diseases\n",
    "Download the [data](https://canvas.supinfo.com/courses/85/files/7110/download?wrap=1) directly from [UCI]()'s website and save it under ./data of your current directory on your host. (/home/jovyan/data in the docker container)\n",
    "## Importing required libraries\n",
    "Always put your imports at the top, it will greatly simplify your work when turning your notebooks into actual python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: pandas_profiling in /opt/conda/lib/python3.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: tqdm==4.42.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (4.42.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (1.18.1)\n",
      "Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.25.3)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.1.12)\n",
      "Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (2.22.0)\n",
      "Requirement already satisfied: phik==0.9.9 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.9.9)\n",
      "Requirement already satisfied: missingno==0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.4.2)\n",
      "Requirement already satisfied: jinja2==2.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (2.11.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (1.4.1)\n",
      "Requirement already satisfied: confuse==1.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (1.0.0)\n",
      "Requirement already satisfied: kaggle==1.5.6 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (1.5.6)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (3.1.3)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.0.3 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.0.3)\n",
      "Requirement already satisfied: astropy>=3.2.3 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (4.0)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (7.5.1)\n",
      "Requirement already satisfied: visions==0.2.2 in /opt/conda/lib/python3.7/site-packages (from pandas_profiling) (0.2.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->pandas_profiling) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->pandas_profiling) (2.8.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->pandas_profiling) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->pandas_profiling) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->pandas_profiling) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->pandas_profiling) (3.0.4)\n",
      "Requirement already satisfied: pytest-pylint>=0.13.0 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (0.15.0)\n",
      "Requirement already satisfied: nbconvert>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (5.6.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.3 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (5.3.4)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (0.14.1)\n",
      "Requirement already satisfied: numba>=0.38.1 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (0.48.0)\n",
      "Requirement already satisfied: pytest>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from phik==0.9.9->pandas_profiling) (5.3.5)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from missingno==0.4.2->pandas_profiling) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2==2.11.1->pandas_profiling) (1.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from confuse==1.0.0->pandas_profiling) (5.3)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle==1.5.6->pandas_profiling) (4.0.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle==1.5.6->pandas_profiling) (1.14.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.3->pandas_profiling) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.3->pandas_profiling) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.3->pandas_profiling) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.5.1->pandas_profiling) (5.0.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.5.1->pandas_profiling) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.5.1->pandas_profiling) (5.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.5.1->pandas_profiling) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.5.1->pandas_profiling) (7.11.1)\n",
      "Requirement already satisfied: attr in /opt/conda/lib/python3.7/site-packages (from visions==0.2.2->pandas_profiling) (0.3.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from visions==0.2.2->pandas_profiling) (2.4)\n",
      "Requirement already satisfied: pylint>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (2.4.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (2.5.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (4.6.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (0.4.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (3.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (1.4.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas_profiling) (18.1.1)\n",
      "Requirement already satisfied: tornado>=4.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas_profiling) (6.0.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.38.1->phik==0.9.9->pandas_profiling) (45.1.0.post20200119)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.38.1->phik==0.9.9->pandas_profiling) (0.31.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (1.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (19.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (1.8.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (0.1.8)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (0.13.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik==0.9.9->pandas_profiling) (20.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle==1.5.6->pandas_profiling) (1.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas_profiling) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas_profiling) (3.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas_profiling) (6.0.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets==7.5.1->pandas_profiling) (4.4.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (3.0.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (0.16.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (0.1.0)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in /opt/conda/lib/python3.7/site-packages (from pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (0.6.1)\n",
      "Requirement already satisfied: astroid<2.4,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (2.3.3)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in /opt/conda/lib/python3.7/site-packages (from pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (4.3.21)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert>=5.3.1->phik==0.9.9->pandas_profiling) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik==0.9.9->pandas_profiling) (2.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.5.1->pandas_profiling) (0.15.7)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas_profiling) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas_profiling) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas_profiling) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied: wrapt==1.11.* in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (1.11.2)\n",
      "Requirement already satisfied: lazy-object-proxy==1.4.* in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (1.4.3)\n",
      "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas_profiling) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation:\n",
    "import pandas as pd\n",
    "\n",
    "# Data exploration:\n",
    "!pip install pandas_profiling\n",
    "import pandas_profiling as pp\n",
    "\n",
    "# scikit learn ML models\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# cross validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df = pd.read_csv('../data/HeartDiseaseUCI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "### What you need to understand\n",
    "A very good tutorial on data exploration: [kaggle tutorial](https://www.kaggle.com/pavansanagapati/a-simple-tutorial-on-exploratory-data-analysis/notebook)\n",
    "\n",
    "### And the quick win version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894b27bd0a5f4647b28ee9a19758997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='variables', max=15.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1674b0fb29b448696ee743ad27d21e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='correlations', max=6.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000f8e219fcb4183acc5f20a899b6427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='interactions [continuous]', max=36.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e8d8a04cbf4c0d818b9d282cb8787c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='table', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c0134a88d543aa91716198b506ac67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='missing', max=4.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ac93190a764c7ea6357cf563694d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='warnings', max=3.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fac493e92941bc8e8e333ef7fb8994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='package', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d01d200b644acc91185454f2380b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='build report structure', max=1.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = '../data'\n",
    "\n",
    "# Get raw bookings file statistic report\n",
    "data_report = pp.ProfileReport(heart_disease_df)\n",
    "data_report.to_file(output_file='{}/heart_disease_report.html'.format(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c42473019f492fb94c3c7fad7f1047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_report.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "We replace the varying degree of disease with a binary classification: healthy/sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0           1   63    1   1       145   233    1        2      150      0   \n",
       "1           2   67    1   4       160   286    0        2      108      1   \n",
       "\n",
       "   oldpeak  slope   ca  thal      num  \n",
       "0      2.3      3  0.0   6.0  healthy  \n",
       "1      1.5      2  3.0   3.0     sick  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_num_df = heart_disease_df.copy()\n",
    "\n",
    "categorical_num_df['num'] = categorical_num_df['num'].apply(\n",
    "    lambda x: 'healthy' if x == 0 else 'sick'\n",
    ")\n",
    "categorical_num_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because scikit learn models only work with numerical values, we need to replace our *healthy* and *sick* labels. There are two potnetial of turning this into numerical values:\n",
    " * Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0           1   63    1   1       145   233    1        2      150      0   \n",
       "1           2   67    1   4       160   286    0        2      108      1   \n",
       "\n",
       "   oldpeak  slope   ca  thal  num  \n",
       "0      2.3      3  0.0   6.0    0  \n",
       "1      1.5      2  3.0   3.0    1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoded_df = categorical_df.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(label_encoded_df['num'])\n",
    "label_encoded_df['num'] = le.transform(label_encoded_df['num'])\n",
    "\n",
    "labeled_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num_healthy</th>\n",
       "      <th>num_sick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0           1   63    1   1       145   233    1        2      150      0   \n",
       "1           2   67    1   4       160   286    0        2      108      1   \n",
       "\n",
       "   oldpeak  slope   ca  thal  num_healthy  num_sick  \n",
       "0      2.3      3  0.0   6.0            1         0  \n",
       "1      1.5      2  3.0   3.0            0         1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(categorical_df).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick win:\n",
    "One-liner that we could have used directly, after understanding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0           1   63    1   1       145   233    1        2      150      0   \n",
       "1           2   67    1   4       160   286    0        2      108      1   \n",
       "\n",
       "   oldpeak  slope   ca  thal  num  \n",
       "0      2.3      3  0.0   6.0    0  \n",
       "1      1.5      2  3.0   3.0    1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_df['num'] = heart_disease_df['num'].apply(lambda x: 0 if x == 0 else 1)\n",
    "heart_disease_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease_df[[ \n",
    "    col for col in heart_disease_df.columns if col not in ['num', 'Unnamed: 0']\n",
    "]]\n",
    "y = heart_disease_df['num']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train: (212, 13)', 'y_train: (212,)', 'X_test: (91, 13)', 'y_test: (91,)']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "211   38    1   1       120   231    0        0      182      1      3.8   \n",
       "67    54    1   3       150   232    0        2      165      0      1.6   \n",
       "25    50    0   3       120   219    0        0      158      0      1.6   \n",
       "196   69    1   1       160   234    1        2      131      0      0.1   \n",
       "175   57    1   4       152   274    0        0       88      1      1.2   \n",
       "\n",
       "     slope   ca  thal  \n",
       "211      2  0.0   7.0  \n",
       "67       1  0.0   7.0  \n",
       "25       2  0.0   3.0  \n",
       "196      2  1.0   3.0  \n",
       "175      2  1.0   7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "211    1\n",
       "67     0\n",
       "25     0\n",
       "196    0\n",
       "175    1\n",
       "Name: num, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    [\n",
    "        'X_train: {}'.format(X_train.shape), 'y_train: {}'.format(y_train.shape), \n",
    "        'X_test: {}'.format(X_test.shape), 'y_test: {}'.format(y_test.shape)\n",
    "    ],\n",
    "    X_train.tail(),\n",
    "    y_train.tail()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "Pipelines in scikit learn are a very important concept. They encapsulate a number of **transformers** and **estimators**.\n",
    "\n",
    "**Transformers** apply a function over your data to modify it, commonly used to apply preprocessing steps over the data before training a model.\n",
    "\n",
    "**Estimators** apply a ML model to make predictions.\n",
    "\n",
    "These are the steps we'll take when [preprocessing our data with scikit learn](https://scikit-learn.org/stable/modules/preprocessing.html) before we can apply our model:\n",
    " * [Fill in missing values](https://scikit-learn.org/stable/modules/impute.html). We will use the [Simple Imputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html).\n",
    " * Scale and center the data with the [Standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to reduce feature range impact for enclidian distances. \n",
    " * We can also conduct a [Principal Component Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the number of dimensions and extract meaningful informations from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classification model: [K-Neirest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "Simple pipeline example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 4) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 4) Processing pca, total=   0.0s\n",
      "[Pipeline] .... (step 4 of 4) Processing knn_classifier, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8021978021978022"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe_example = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=12)),\n",
    "        ('knn_classifier', KNeighborsClassifier(n_neighbors=10))\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "knn_pipe_example.fit(X_train, y_train)\n",
    "knn_pipe_example.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the same with python *list* and *dict* comprehension to reuse the same preprocessing steps for every model we'll test, along with a **cross_validate** utility function to perform grid search with multiple hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_steps = [\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=12))\n",
    "]\n",
    "preprocessing_params = {\n",
    "    'imputer__strategy': ['mean', 'median'],\n",
    "    'scaler__with_mean': [True, False],\n",
    "    'scaler__with_std': [True, False],\n",
    "    'pca__n_components': [11, 12, 13]\n",
    "}\n",
    "\n",
    "def cross_validate(model, params):\n",
    "    # create a gridsearch of the pipeline, the find the best hyper parameters\n",
    "    grid_param = { **preprocessing_params, **params }\n",
    "    gridsearch = GridSearchCV(model, grid_param, cv=5, verbose=1, n_jobs=-1)\n",
    "    gridsearch_result = gridsearch.fit(X_train, y_train)\n",
    "\n",
    "    display(gridsearch_result.best_estimator_)\n",
    "    display('Best model accuracy over previously unseen data: {}'.format(\n",
    "        gridsearch_result.score(X_test, y_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1820 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=12,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 KNeighborsClassifier(algorithm='brute', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=10, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8021978021978022'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    preprocessing_steps + [('classifier', KNeighborsClassifier())]\n",
    ")\n",
    "knn_params = {\n",
    "    'classifier__n_neighbors': [5, 10, 15, 20],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__algorithm': ['brute', 'ball_tree']\n",
    "}\n",
    "\n",
    "cross_validate(knn_pipe, knn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classification model: [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=12,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=0.5, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=0,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8131868131868132'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = preprocessing_steps + [('classifier', LinearSVC(random_state=0))]\n",
    ")\n",
    "svm_params = {\n",
    "    'classifier__C': [0.5, 1, 1.5],\n",
    "    'classifier__loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "\n",
    "cross_validate(svm_pipe, svm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classification model: [Linear Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=False)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=11,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 LinearDiscriminantAnalysis(n_components=None, priors=None,\n",
       "                                            shrinkage=None, solver='svd',\n",
       "                                            store_covariance=False,\n",
       "                                            tol=0.0001))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8131868131868132'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda_pipe = Pipeline(\n",
    "    steps = preprocessing_steps + [('classifier', LinearDiscriminantAnalysis())]\n",
    ")\n",
    "lda_params = {\n",
    "    'classifier__solver': ['svd', 'lsqr', 'eigen']\n",
    "}\n",
    "\n",
    "cross_validate(lda_pipe, lda_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classification model: [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=False)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=11,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8571428571428571'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnb_pipe = Pipeline(steps = preprocessing_steps + [('classifier', GaussianNB())])\n",
    "gnb_params = {}\n",
    "\n",
    "cross_validate(gnb_pipe, gnb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classification model: [Logistic regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 949 out of 960 | elapsed:    4.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=12,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.5, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8131868131868132'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_pipe = Pipeline(preprocessing_steps + [('classifier', LogisticRegression())])\n",
    "lr_params = {\n",
    "    'classifier__C': [0.1, 0.5, 1, 1.5],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "cross_validate(lr_pipe, lr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out different setups: [Cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) over multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 816 candidates, totalling 8160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2060 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6060 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 8160 out of 8160 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=False)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=11,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best model accuracy over previously unseen data: 0.8131868131868132'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline(preprocessing_steps + [('classifier', LogisticRegression())])\n",
    "\n",
    "# Create list with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "    { \n",
    "        'classifier': [KNeighborsClassifier()], \n",
    "        **preprocessing_params, \n",
    "        **knn_params \n",
    "    },\n",
    "    { \n",
    "        'classifier': [LinearSVC()], \n",
    "        **preprocessing_params, \n",
    "        **svm_params \n",
    "    },\n",
    "    { \n",
    "        'classifier': [LinearDiscriminantAnalysis()], \n",
    "        **preprocessing_params, \n",
    "        **lda_params\n",
    "    },\n",
    "    { \n",
    "        'classifier': [GaussianNB()], \n",
    "        **preprocessing_params, \n",
    "        **gnb_params \n",
    "    },\n",
    "    { \n",
    "        'classifier': [LogisticRegression()], \n",
    "        **preprocessing_params, \n",
    "        **lr_params \n",
    "    }\n",
    "]\n",
    "\n",
    "# create a gridsearch of the pipeline, then fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=10, verbose=1, n_jobs=-1)\n",
    "gridsearch_result = gridsearch.fit(X_train, y_train)\n",
    "\n",
    "display(gridsearch_result.best_estimator_)\n",
    "display('Best model accuracy over previously unseen data: {}'.format(\n",
    "    gridsearch_result.score(X_test, y_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
